{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a04b3010",
   "metadata": {},
   "source": [
    "# Test 1\n",
    "\n",
    "The Massively Multilingual Image Dataset (MMID)\n",
    "\n",
    "Dataset page: https://aws.amazon.com/marketplace/pp/prodview-f25bmlrgfo7bu?sr=0-69&ref_=beagle&applicationId=AWSMPContessa#overview\n",
    "\n",
    "MMID is a large-scale, massively multilingual dataset of images paired with the words they represent collected at the University of Pennsylvania . The dataset is doubly parallel: for each language, words are stored parallel to images that represent the word, and parallel to the word's translation into English (and corresponding images.)\n",
    "\n",
    "License: See citation instructions at http://multilingual-images.org \n",
    "\n",
    "Documentation: https://multilingual-images.org/doc.html \n",
    "\n",
    "How to cite: The Massively Multilingual Image Dataset (MMID) was accessed on DATE from https://registry.opendata.aws/mmid .\n",
    "\n",
    "Description\n",
    "Images for words in various languages, packaged by in .tar archives by each language.\n",
    "\n",
    "Resource type: S3 Bucket\n",
    "Amazon Resource Name (ARN): `arn:aws:s3:::mmid-pds`\n",
    "\n",
    "AWS Region: `us-east-1`\n",
    "AWS CLI Access (No AWS account required): `aws s3 ls --no-sign-request s3://mmid-pds/`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a8fab3",
   "metadata": {},
   "source": [
    "Sample data is located under `sample_data/`\n",
    "\n",
    "The idea is for each word, there will be a bunch of images. \n",
    "\n",
    "Note for Mini Image Package: The form of the mini image package is identical to that of the full image package, to aid rapid development. It just has 1 image per word instead of 100.\n",
    "\n",
    "In the poster of MMID ACN paper, AlexNet was used. Can we try other architectures?\n",
    "\n",
    "https://towardsdatascience.com/architecture-comparison-of-alexnet-vggnet-resnet-inception-densenet-beb8b116866d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa30a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing, try using folder 996 (image of Alps)\n",
    "# mini-package (tar/un-tar): 400 MB/ 1.2 GiB\n",
    "# full (scale): 16 GiB/ XXX (probably ~ 50 GiB)\n",
    "\n",
    "# breakdown the task into components, initially using the mini-package:\n",
    "# aws s3 ls --human-readable --no-sign-request s3://mmid-pds/language_image_packages/scale-arabic-package.tgz\n",
    "# aws s3 ls --human-readable --no-sign-request s3://mmid-pds/mini_language_image_packages/mini-arabic-package.tgz\n",
    "\n",
    "\n",
    "# 1. use AlexNet, read data on S3 (no need to do local download), use Hadoop or \n",
    "# some other distributed learning (Spark?) --> use AWS EMR\n",
    "# check this: https://aws.amazon.com/emr/features/studio/?nc=sn&loc=2&dn=3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-base",
   "language": "python",
   "name": "conda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
